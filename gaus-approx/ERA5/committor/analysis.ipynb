{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3f4398-8841-4af2-a936-c9d3a6e1763f",
   "metadata": {},
   "source": [
    "# Analysis of the Gaussian committor\n",
    "\n",
    "In this notebook you will see how to train the Gaussian committor and analyze the results to generate the figures in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348fed24-0a11-4494-8128-35d79023a9d9",
   "metadata": {},
   "source": [
    "## Compute the Gaussian committor\n",
    "\n",
    "To compute the Gaussian committor, we will use the [Climate-Learning](https://github.com/georgemilosh/Climate-Learning) repository, and in particular the code in `Climate-Learning/PLASIM/gaussian_approx.py`\n",
    "\n",
    "Remember from the general documentation, that you should clone the repository in on the same level as `gaus-approx`. See the general `README.md` for more info.\n",
    "\n",
    "If you are curious about the implementation, you can look at the code mentioned and in particular at the `GaussianCommittor` object, which can be easily used outside the Climate-Learning framework.\n",
    "\n",
    "---\n",
    "\n",
    "### Create working directory\n",
    "\n",
    "To proceed with the computations, first open a terminal in `Climate-Learning/PLASIM` and run\n",
    "\n",
    "```bash\n",
    "python gaussian_approx.py ../../gaus-approx/ERA5/committor/ga/\n",
    "```\n",
    "\n",
    "which will create the directory `../../gaus-approx/ERA5/committor/ga/`, where you have all the tools to train the gaussian committor. Then `cd` into it\n",
    "\n",
    "The choice of the path `../../gaus-approx/ERA5/committor/ga/` is arbitrary, but if you use this one, you'll be able to run the rest of this notebook without any changes.\n",
    "\n",
    "### Setup config file\n",
    "\n",
    "Once you are in (relative to the path of this notebook) `ga/`, run\n",
    "\n",
    "```bash\n",
    "python import_config.py ../config_T14_tau0_epsilon1.json\n",
    "```\n",
    "\n",
    "Which will set up the training to be performed exactly as it was for the paper.\n",
    "\n",
    "### Run\n",
    "\n",
    "The `Climate-Learning` framework is optimized to do multiple trainings in series, minimizing data reloads. To have the data you will need for the results in the paper, from `ga/` launch\n",
    "\n",
    "```bash\n",
    "python gaussian_approx.py T=\"[1,7,14]\" tau=\"[0,-1,-2,-3,-4,-5,-6,-7,-10,-15,-20,-25,-30]\" reg_c=\"[0,1e-2,1e-1,1,1e1,1e2,1e3,1e4,1e5,1e6,1e7]\"\n",
    "```\n",
    "\n",
    "Notice that the code uses the convention $\\tau < 0$ for a forecast in the future. `reg_c` is the regularization coefficient $\\epsilon$.\n",
    "\n",
    "Be wary that depending on your machine, these calculations may take a while. You can of course change the parameter combinations that you look at to speed up the process, for example reducing the number of regularization coefficients\n",
    "\n",
    "\n",
    "#### Prediction using the composite map\n",
    "\n",
    "In figure 9, we show the prediction using the composite map as a projection pattern. To compute this in practice we exploit the fact that when we do $L_2$ regularization,\n",
    "\n",
    "$$ \\lim_{\\epsilon \\to \\infty} M_\\epsilon \\propto \\Sigma_{XA} \\propto C$$\n",
    "\n",
    "So, launch (in the same directory `ga`)\n",
    "\n",
    "```bash\n",
    "python gaussian_approx.py T=14 tau=\"[0,-1,-2,-3,-4,-5,-6,-7,-10,-15,-20,-25,-30]\" reg_c=1e8 regularization=\"identity\"\n",
    "```\n",
    "\n",
    "\n",
    "## Train convolutional neural network\n",
    "\n",
    "### Create working directory\n",
    "\n",
    "To train the convolutional networks we'll proceed in a very similar way. Go in `Climate-Learning/PLASIM` and run\n",
    "\n",
    "```bash\n",
    "python Learn2_new.py ../../gaus-approx/ERA5/committor/cnn/\n",
    "```\n",
    "\n",
    "### Setup config file\n",
    "\n",
    "Move to `cnn/` and set up the config file\n",
    "\n",
    "```bash\n",
    "python import_config.py ../config_T14_tau0_epsilon1.json\n",
    "```\n",
    "\n",
    "After this open `cnn/config.json` and check that `load_from` is set to `null`. The default value of `'last'` would do transfer learning from the last compatible training. If you want you can try this option as well, but we observed it didn't make much of a difference.\n",
    "\n",
    "### Run\n",
    "\n",
    "From `cnn/`, launch\n",
    "\n",
    "```bash\n",
    "python Learn2_new.py T=14 tau=\"[0,-1,-2,-3,-4,-5,-6,-7,-10,-15,-20,-25,-30]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc5ef72-abfa-450e-9c05-f05a7800944e",
   "metadata": {},
   "source": [
    "## Collect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff780ca-45f7-40ff-a65a-47d0903290b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "matplotlib.rc('font', size=18)\n",
    "default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy import sparse\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../Climate-Learning/')\n",
    "\n",
    "import general_purpose.utilities as ut\n",
    "import general_purpose.cartopy_plots as cplt\n",
    "import general_purpose.uplotlib as uplt\n",
    "# import general_purpose.tables as tbl\n",
    "\n",
    "# log to stdout\n",
    "import logging\n",
    "logging.getLogger().level = logging.INFO\n",
    "logging.getLogger().handlers = [logging.StreamHandler(sys.stdout)]\n",
    "ut.indentation_sep = '  '\n",
    "\n",
    "HOME = '../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693b468-8842-490f-be61-d536a6763bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2(x, **kwargs):\n",
    "    return np.sqrt(np.sum(x**2, **kwargs))\n",
    "\n",
    "def get_score(run):\n",
    "    return uplt.unc.ufloat(run['scores']['mean'], run['scores']['std'])\n",
    "\n",
    "def get_arg(run, key, config_dict):\n",
    "    return run['args'].get(key, ut.extract_nested(config_dict, key))\n",
    "\n",
    "def get_years(run, config_dict):\n",
    "    try:\n",
    "        year_list = run['args']['year_list']\n",
    "    except KeyError:\n",
    "        year_list = ut.extract_nested(config_dict, 'year_list')\n",
    "        \n",
    "    if year_list is None:\n",
    "        return ut.extract_nested(config_dict, 'dataset_years')\n",
    "    \n",
    "    year_list = f\"({year_list.split('(',1)[1].split(')',1)[0]})\" # get just the arguments\n",
    "    year_list = ast.literal_eval(year_list) # now year_list is int or tuple\n",
    "\n",
    "    if isinstance(year_list,int):\n",
    "        return year_list\n",
    "    elif isinstance(year_list, tuple):\n",
    "        return np.arange(*year_list).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219bff50-4055-428c-8eda-d447ef6fcfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = np.load('../../lon.npy')\n",
    "lat = np.load('../../lat.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7148083b-346e-4293-92b0-b5b991e4ba67",
   "metadata": {},
   "source": [
    "### Compute skill of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b4bbf8-23f5-4afe-be7a-2e606cef1a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PLASIM.Learn2_new as ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59960cea-1faf-4e31-91df-d207ef26d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_ERA_CNN = 'cnn/'\n",
    "runs_ERA_CNN = ut.json2dict(f'{folder_ERA_CNN}/runs.json')\n",
    "runs_ERA_CNN = {k:v for k,v in runs_ERA_CNN.items() if v['status'] == 'COMPLETED'}\n",
    "config_dict_ERA_CNN = ut.json2dict(f'{folder_ERA_CNN}/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a589611-f659-4298-9b4a-14f420aee328",
   "metadata": {},
   "outputs": [],
   "source": [
    "var='tau'\n",
    "groups_ERA_CNN = ln.make_groups(runs_ERA_CNN, variable=var, config_dict_flat=ut.collapse_dict(config_dict_ERA_CNN), sort=True)\n",
    "for g in groups_ERA_CNN:\n",
    "    print(g['args'], g[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d562f6-fae6-4a0a-8a1c-56b0ef97b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_CNN = groups_ERA_CNN[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd711d-6bda-422f-89a0-720bce255d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "item = {}\n",
    "\n",
    "for run in g_CNN['runs']:\n",
    "    nfolds = get_arg(run, 'nfolds',)\n",
    "    item['tau'] = -get_kwarg(run, 'tau', config_dict_ERA_CNN)\n",
    "    # print(item['tau'])\n",
    "    for fold in range(nfolds):\n",
    "        item['fold'] = fold\n",
    "        item['skill'] = 1 - run['scores'][f'fold_{fold}']/ut.entropy(0.05)\n",
    "        df.append(item.copy())\n",
    "df = pd.DataFrame(df)\n",
    "df.sort_values(['tau', 'fold'], inplace=True)\n",
    "dfi = df.set_index(['tau', 'fold'])\n",
    "ds = dfi.to_xarray()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1849b0d-2e1f-4faa-8859-7178d733949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds['skill'].expand_dims({'T': [14], 'percent': [5]})\n",
    "ds.attrs = {'description': 'Normalized log score of CNN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27165940-c52a-421d-b530-b4b1fb5987a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf('Skill-CNN_T14_percent5.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1a3a2-f763-4fa9-a37d-66e0337df86f",
   "metadata": {},
   "source": [
    "### Compute skill of composite map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c362f4-1fc5-4f11-ab72-79f6bf2e4d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'ga'\n",
    "runs = ut.json2dict(f'{folder}/runs.json')\n",
    "runs = {k:v for k,v in runs.items() if v['status'] == 'COMPLETED'}\n",
    "config_dict = ut.json2dict(f'{folder}/config.json')\n",
    "\n",
    "runs = {k:v for k,v in runs.items() if 'T' not in v['args'] and get_arg(v, 'regularization', config_dict) == 'identity'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f94ab7-9a85-4e27-ba48-0468500463fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_g = ln.make_groups(runs, variable='tau', config_dict_flat=ut.collapse_dict(config_dict), sort=True)[0]\n",
    "id_g['args'], id_g['tau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b19f4-029f-4aa7-9d9a-b335f4f8004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "item = {}\n",
    "\n",
    "for run in id_g['runs']:\n",
    "    nfolds = get_arg(run, 'nfolds',)\n",
    "    item['tau'] = -get_kwarg(run, 'tau', config_dict_ERA_CNN)\n",
    "    # print(item['tau'])\n",
    "    for fold in range(nfolds):\n",
    "        item['fold'] = fold\n",
    "        item['skill'] = 1 - run['scores'][f'fold_{fold}']/ut.entropy(0.05)\n",
    "        df.append(item.copy())\n",
    "df = pd.DataFrame(df)\n",
    "df.sort_values(['tau', 'fold'], inplace=True)\n",
    "dfi = df.set_index(['tau', 'fold'])\n",
    "ds = dfi.to_xarray()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f5e1f-142e-4983-9e2c-15cc81336c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds['skill'].expand_dims({'T': [14], 'percent': [5]})\n",
    "ds.attrs = {'description': 'Normalized log score of Gaussian approximation when projecting onto the composite map'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c2fd1-7a60-45bc-9f4f-79150e4ec8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf('Skill-comp_T14_percent5.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1393567-a0cb-4174-984c-a92ddcc73379",
   "metadata": {},
   "source": [
    "### Compute $H_2$ of projection patterns (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2c949-d669-4752-af55-0e5176c23b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones((22,128,1), dtype=bool)\n",
    "reshaper = ut.Reshaper(mask)\n",
    "\n",
    "coslat = np.maximum(np.cos(lat*np.pi/180), 0)\n",
    "aw = (np.ones(mask.shape).T * coslat).T\n",
    "aw *= mask\n",
    "aw /= np.sum(aw)\n",
    "\n",
    "W = sparse.load_npz('W.npz')\n",
    "\n",
    "assert W.shape[0] == reshaper.surviving_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b06caf-3bf5-46c5-a77b-5264bd84f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'ga'\n",
    "\n",
    "config_dict = ut.json2dict(f'{folder}/config.json')\n",
    "\n",
    "runs = ut.json2dict(f'{folder}/runs.json')\n",
    "\n",
    "nfolds = ut.extract_nested(config_dict, 'nfolds')\n",
    "\n",
    "force_computation = False\n",
    "\n",
    "\n",
    "for run in tqdm(reversed(runs.values())):\n",
    "    if run['status'] != 'COMPLETED' or ('h2s' in run and not force_computation):\n",
    "        continue\n",
    "    # print(run['name'])\n",
    "    h2s = {}\n",
    "    for fold in range(nfolds):\n",
    "        proj = np.load(f\"{folder}/{run['name']}/fold_{fold}/proj.npy\")\n",
    "        \n",
    "        # normalize projection pattern\n",
    "        proj /= l2(proj*np.sqrt(aw))\n",
    "        \n",
    "        proj_r = reshaper.reshape(proj)\n",
    "        h2 = proj_r @ W @ proj_r\n",
    "        \n",
    "        h2s[f'fold_{fold}'] = h2\n",
    "    h2m = np.mean(list(h2s.values()))\n",
    "    h2z = np.std(list(h2s.values()))\n",
    "    h2s['mean'] = h2m\n",
    "    h2s['std'] = h2z\n",
    "    \n",
    "    run['h2s'] = h2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824905a9-e2e8-46c0-bf0b-ca6acfd981b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.dict2json(runs, f'{folder}/runs.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230cafa-6be6-45cc-b6d3-e45102e9159e",
   "metadata": {},
   "source": [
    "### Compute skill of GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f1e99-f398-4863-b314-eb0c7ca5f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all runs in a big dataframe\n",
    "\n",
    "df = []\n",
    "item = {}\n",
    "fields = None\n",
    "year_list = None\n",
    "\n",
    "folders = ['ga']\n",
    "Model = 'ERA5'\n",
    "\n",
    "\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    runs = ut.json2dict(f'{folder}/runs.json')\n",
    "    runs = {k:v for k,v in runs.items() if v['status'] == 'COMPLETED'}\n",
    "    config_dict = ut.json2dict(f'{folder}/config.json')\n",
    "    \n",
    "    for run in tqdm(runs.values()):\n",
    "        \n",
    "        if get_arg(run, 'regularization', config_dict) != ut.extract_nested(config_dict, 'regularization'): # ignore other regularization types\n",
    "            continue\n",
    "        if fields is not None:\n",
    "            if get_arg(run, 'fields', config_dict) != fields:\n",
    "                continue\n",
    "        if year_list is not None:\n",
    "            if get_arg(run, 'year_list', config_dict) != year_list:\n",
    "                continue\n",
    "        \n",
    "        item['path'] = f\"{folder}/{run['name']}\"\n",
    "        for kw in ['T', 'tau', 'reg_c', 'percent']:\n",
    "            item[kw] = get_arg(run, kw, config_dict)\n",
    "        item['tau'] = -item['tau']\n",
    "        item['years'] = get_years(run, config_dict)\n",
    "        # item['run'] = run\n",
    "        \n",
    "        item['clim_entropy'] = ut.entropy(0.01*item['percent'])\n",
    "        \n",
    "        nfolds = get_arg(run, 'nfolds', config_dict)\n",
    "        for fold in range(nfolds):\n",
    "            item['fold'] = fold\n",
    "            item['entropy'] = run['scores'][f'fold_{fold}']\n",
    "        \n",
    "            try:\n",
    "                item['h2'] = run['h2s'][f'fold_{fold}']\n",
    "            except KeyError:\n",
    "                item['h2'] = np.nan\n",
    "                \n",
    "            \n",
    "            \n",
    "        # item['field_ratio'] = get_field_ratio(folder, run)\n",
    "            df.append(item.copy())\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "df.sort_values(['T', 'tau', 'percent', 'reg_c', 'years', 'fold'], inplace=True)\n",
    "\n",
    "assert not df.duplicated(['T', 'tau', 'reg_c', 'years', 'fold']).any()\n",
    "\n",
    "df['skill'] = 1 - df['entropy']/df['clim_entropy']\n",
    "dfi = df.set_index(['T', 'tau', 'reg_c', 'years', 'fold'])\n",
    "ds = dfi.to_xarray()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247469e-585f-46d5-b2be-a16110e50a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = ds['skill']\n",
    "sk.attrs = {'description': 'Normalized log score of Gaussian approximation'}\n",
    "sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c52a9-d407-41b8-8fdb-bf59bb46377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_best = sk.mean('fold').fillna(-100).argmax('reg_c')\n",
    "eps_best\n",
    "skk = sk.isel(reg_c=eps_best)\n",
    "skk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f4c56-4b2a-4497-8087-86ebd39484a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skk.to_netcdf('Skill-GA_percent5_epsilonbest.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bb2419-8a59-48d9-a5d8-71463a0542d0",
   "metadata": {},
   "source": [
    "### Save projection patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c2944-5cd0-4de1-82b6-9638842aa0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones((22,128,1), dtype=bool)\n",
    "reshaper = ut.Reshaper(mask)\n",
    "\n",
    "coslat = np.maximum(np.cos(lat*np.pi/180), 0)\n",
    "aw = (np.ones(mask.shape).T * coslat).T\n",
    "aw *= mask\n",
    "aw /= np.sum(aw)\n",
    "\n",
    "W = sparse.load_npz('W.npz')\n",
    "\n",
    "assert W.shape[0] == reshaper.surviving_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fda95c-85d0-4792-8a51-5a6f256cf5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = ds.isel(reg_c=eps_best)\n",
    "ss = sel.sel(T=1,tau=[0,2,4,6],fold=0)\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c62749-95b4-47e0-8422-a77560b7045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "projs = []\n",
    "for tau in ss['tau'].data:\n",
    "    sss = ss.sel(tau=tau)\n",
    "    proj = np.load(f'{sss[\"path\"].data.item()}/fold_0/proj.npy')\n",
    "    proj /= l2(proj*np.sqrt(aw))\n",
    "    proj = reshaper.reshape(proj)\n",
    "    projs.append(proj)\n",
    "projs = np.stack(projs)\n",
    "projs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b299a-e7e4-40bd-9ee5-31848543d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.DataArray(projs, coords={'tau': ss['tau'].data, 'pixel': np.arange(projs.shape[1])}, name='M')\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508240de-6cbb-4819-acae-f4905c6daa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.expand_dims({'T': [1], 'fold': [0], 'years': [80]})\n",
    "da.attrs = {'description': 'Projection patterns for the Gaussian approximation'}\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3432d-004d-47c0-8e77-5f43b71e6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.to_netcdf('projection_patterns_T1_epsilonbest_fold0.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ink",
   "language": "python",
   "name": "ink"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
